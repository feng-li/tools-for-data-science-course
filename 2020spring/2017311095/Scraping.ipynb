{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Scraping http://shenzhen.sina.com.cn/news/n/2020-04-09/detail-iirczymi5376128.shtml\n",
      "INFO:root:Scraping https://k.sina.com.cn/article_5044281310_12ca99fde020018uer.html?from=news&subch=onews\n",
      "INFO:root:Scraping https://mil.news.sina.com.cn/2020-04-09/doc-iircuyvh6846470.shtml\n",
      "INFO:root:Scraping https://k.sina.com.cn/article_3147098824_bb94eac8020017xry.html?from=local\n",
      "INFO:root:Scraping https://k.sina.com.cn/article_5044281310_12ca99fde020018uen.html?from=finance\n",
      "INFO:root:Scraping https://k.sina.com.cn/article_1784473157_6a5ce64502001tjus.html?from=news&subch=onews\n",
      "INFO:root:Scraping https://news.sina.com.cn/c/2020-04-09/doc-iircuyvh6845599.shtml\n",
      "INFO:root:Scraping https://zx.sina.cn/e/2020-04-09/zx-iirczymi5375158.d.html\n",
      "INFO:root:Scraping https://k.sina.com.cn/article_5787187353_158f1789902000zkpx.html?from=news&subch=onews\n",
      "INFO:root:Scraping https://k.sina.com.cn/article_6456450127_180d59c4f02000yzzw.html?from=news&subch=onews\n",
      "INFO:root:Scraping https://k.sina.com.cn/article_1784473157_6a5ce64502001tjus.html?from=news&subch=onews\n",
      "INFO:root:Scraping https://news.sina.com.cn/c/2020-04-09/doc-iircuyvh6845599.shtml\n",
      "INFO:root:Scraping https://zx.sina.cn/e/2020-04-09/zx-iirczymi5375158.d.html\n",
      "INFO:root:Scraping https://k.sina.com.cn/article_5787187353_158f1789902000zkpx.html?from=news&subch=onews\n",
      "INFO:root:Scraping https://k.sina.com.cn/article_6456450127_180d59c4f02000yzzw.html?from=news&subch=onews\n",
      "INFO:root:Scraping https://k.sina.com.cn/article_2810373291_a782e4ab02001nk66.html?from=news&subch=onews\n",
      "INFO:root:Scraping https://finance.sina.com.cn/roll/2020-04-09/doc-iirczymi5375039.shtml\n",
      "INFO:root:Scraping https://k.sina.com.cn/article_1662558237_6318a01d01900qau4.html?from=news&subch=onews\n",
      "INFO:root:Scraping https://k.sina.com.cn/article_1784473157_6a5ce64502001tju8.html?from=news&subch=onews\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import requests\n",
    "import sys\n",
    "import urllib\n",
    "import bs4\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "\n",
    "def get_list(words, page):\n",
    "\n",
    "    newsData = OrderedDict()\n",
    "    href = 'http://search.sina.com.cn/?%s&c=news&from=&col=&range=all&source=&country=&size=10&time=&dpc=0&a=&ps=0&pf=0&page=%s' % (words, page)\n",
    "    html = requests.get(href)\n",
    "    soup = BeautifulSoup(html.content, 'html.parser')\n",
    "    divs = soup.findAll('div', {\"class\": \"r-info r-info2\"})\n",
    "    for div in divs:\n",
    "        head = div.findAll('h2')[0]\n",
    "        titleinfo = head.find('a')\n",
    "        title = titleinfo.get_text()\n",
    "        url = titleinfo['href']\n",
    "        otherinfo = head.find('span', {\"class\": \"fgray_time\"}).get_text()\n",
    "        source, date, time = otherinfo.split()\n",
    "        abstract = div.find('p', {\"class\": \"content\"}).get_text()\n",
    "        newsData[title] = [source, date,time, abstract, url]\n",
    "    return newsData\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    wordsRawStr = '新冠病毒'\n",
    "    words = wordsRawStr.encode('gbk')\n",
    "    d = {'q': words}\n",
    "    pname = urlencode(d)\n",
    "    news=[]\n",
    "    for page in range(1,10):\n",
    "        newsData = get_list(pname, page)\n",
    "        for ky in newsData:\n",
    "            a = '\\001'.join([ky] + newsData[ky])\n",
    "            news.append(a)\n",
    "            \n",
    "news = pd.DataFrame(data = news)\n",
    "news.to_csv(\"C:/Users/lenovo/Desktop/news.txt\")\n",
    "with open(\"C:/Users/lenovo/Desktop/news.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "with open(\"C:/Users/lenovo/Desktop/news.txt\",\"w\",encoding=\"utf-8\") as f_w:\n",
    "    for line in lines:\n",
    "        if \",0\" in line:\n",
    "            continue\n",
    "        f_w.write(line)\n",
    "\n",
    "def get_body(href):\n",
    "    html = requests.get(href)\n",
    "    soup = BeautifulSoup(html.content, 'html.parser')\n",
    "    div = soup.find('div',{\"id\":\"artibody\"})\n",
    "    content=''#以解决局部变量和全局变量的问题\n",
    "    if isinstance(div,bs4.element.Tag):#应对一些中间有无法识别的空格的情况\n",
    "        paras = div.find_all(\"p\")\n",
    "        content = ''\n",
    "        for p in paras:\n",
    "            ptext = p.get_text().strip().replace(\"\\n\",\"\")\n",
    "            content += ptext\n",
    "    return content\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    coronalvirus = []\n",
    "    with open(\"C:/Users/lenovo/Desktop/news.txt\",encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "                slogan,title, source, date, abstract, href = line.strip().split('\\001')\n",
    "                logging.info('Scraping ' + href)\n",
    "                content = get_body(href)\n",
    "                b='\\001'.join([slogan,title, source, date, abstract, href, content])\n",
    "                coronalvirus.append(b)\n",
    "news = pd.DataFrame(data = coronalvirus)\n",
    "news.to_csv(\"C:/Users/lenovo/Desktop/coronalvirus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
